import os
import json
import httpx
import logging
from pathlib import Path
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

def load_prompts(system_prompt_path: str, user_prompt_path: str) -> tuple[str, str]:
    """
    Loads system and user prompts from two separate text files.

    Args:
        system_prompt_path: The file path for the system prompt.
        user_prompt_path: The file path for the user prompt.

    Returns:
        A tuple containing the (system_prompt, user_prompt).

    Raises:
        FileNotFoundError: If either of the files cannot be found.
    """
    try:
        with open(system_prompt_path, 'r', encoding='utf-8') as f:
            system_prompt = f.read().strip()

        with open(user_prompt_path, 'r', encoding='utf-8') as f:
            user_prompt = f.read().strip()

        if not system_prompt or not user_prompt:
            raise ValueError("A prompt file is empty. Please ensure both files have content.")

        return system_prompt, user_prompt

    except FileNotFoundError as e:
        print(f"Error: A prompt file was not found. Details: {e}")
        # Re-raise the exception to be handled by the caller
        raise
    except Exception as e:
        print(f"An unexpected error occurred while loading prompts: {e}")
        raise

def setup_bot():
    """
    Loads environment variables and returns a fully configured Application instance.
    """
    # Load environment variables from .env file
    load_dotenv()
    telegram_bot_token = os.getenv("TELEGRAM_BOT_TOKEN")

    if not telegram_bot_token:
        raise ValueError("TELEGRAM_BOT_TOKEN environment variable not set!")

    # Create the Application instance
    application = Application.builder().token(telegram_bot_token).build()

    # Add the command handler for /generate
    application.add_handler(CommandHandler("generate", generate_post))

    return application

async def generate_post(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Sends a post generated by the LLM."""

    logger.info("Received /generate command from user: %s", update.effective_user.id)
    await update.message.reply_text('Generating a post for you...')

    # It's better to load the API key here, only when needed.
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
    if not openrouter_api_key:
        await update.message.reply_text("Error: OPENROUTER_API_KEY is not configured.")
        return

    project_root = Path(__file__).parent.parent.parent

    system_prompt_file = project_root / "prompts" / "system_prompt.txt"
    user_prompt_file = project_root / "prompts" / "user_prompt.txt"

    system_prompt, user_prompt = load_prompts(
            system_prompt_path=system_prompt_file,
            user_prompt_path=user_prompt_file
        )

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {openrouter_api_key}",
                },
                data=json.dumps({
                    "model": "anthropic/claude-opus-4",
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ]
                })
            )
            response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)
            data = response.json()
            post_text = data['choices'][0]['message']['content']
            await update.message.reply_text(post_text)

    except httpx.HTTPStatusError as e:
        print(f"HTTP error occurred: {e}")
        await update.message.reply_text("Sorry, there was an error communicating with the AI service.")
    except Exception as e:
        print(f"An error occurred: {e}")
        await update.message.reply_text("Sorry, an unexpected error occurred.")